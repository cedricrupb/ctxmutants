{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Realistic Mutations: Bug Creation for Neural Bug Detection\n",
    "This accompanying notebook is an interactive demo for our contextual mutator. The goal is to inject realistic\n",
    "bugs into code based on the code context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the project\n",
    "First, we have to locally install the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'tmp'...\n",
      "remote: Enumerating objects: 132, done.\u001b[K\n",
      "remote: Counting objects: 100% (132/132), done.\u001b[K\n",
      "remote: Compressing objects: 100% (77/77), done.\u001b[K\n",
      "remote: Total 132 (delta 57), reused 127 (delta 52), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (132/132), 66.91 KiB | 2.57 MiB/s, done.\n",
      "Resolving deltas: 100% (57/57), done.\n"
     ]
    }
   ],
   "source": [
    "!mkdir tmp\n",
    "!git clone https://github.com/cedricrupb/ctxmutants.git tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cedricr/Documents/WorkDir/SCAD/ctxmutants/tmp\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: transformers in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (4.3.3)\n",
      "Requirement already satisfied: fasttext in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (0.9.2)\n",
      "Requirement already satisfied: numpy in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.19.5)\n",
      "Requirement already satisfied: esprima in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (4.0.1)\n",
      "Requirement already satisfied: javalang in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (0.13.0)\n",
      "Requirement already satisfied: libcst in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (0.3.19)\n",
      "Requirement already satisfied: typing-extensions in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from torch>=1.8.0->-r requirements.txt (line 1)) (3.7.4.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 2)) (2021.7.6)\n",
      "Requirement already satisfied: filelock in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 2)) (3.0.12)\n",
      "Requirement already satisfied: requests in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 2)) (2.25.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 2)) (0.10.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 2)) (4.61.2)\n",
      "Requirement already satisfied: packaging in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 2)) (21.0)\n",
      "Requirement already satisfied: sacremoses in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 2)) (0.0.43)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from fasttext->-r requirements.txt (line 3)) (58.4.0)\n",
      "Requirement already satisfied: pybind11>=2.2 in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from fasttext->-r requirements.txt (line 3)) (2.7.0)\n",
      "Requirement already satisfied: six in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from javalang->-r requirements.txt (line 6)) (1.15.0)\n",
      "Requirement already satisfied: pyyaml>=5.2 in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from libcst->-r requirements.txt (line 7)) (5.4.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from libcst->-r requirements.txt (line 7)) (0.7.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from typing-inspect>=0.4.0->libcst->-r requirements.txt (line 7)) (0.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from packaging->transformers->-r requirements.txt (line 2)) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 2)) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 2)) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 2)) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 2)) (2.10)\n",
      "Requirement already satisfied: click in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from sacremoses->transformers->-r requirements.txt (line 2)) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Users/cedricr/miniforge3/envs/py38/lib/python3.8/site-packages (from sacremoses->transformers->-r requirements.txt (line 2)) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "%cd tmp\n",
    "\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "import ctxmutants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup preprocessing\n",
    "Now, we can setup the preprocessing pipeline for preprocessing code that should be mutated. Here,\n",
    "we employ a specific syntactic tagger that preserves semantic roles of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['public', 'int', 'additionTest', '(', 'int', 'a', ',', 'int', 'b', ')', '{', 'return', 'a', '+', 'b', ';', '}']\n"
     ]
    }
   ],
   "source": [
    "code_example = \"\"\"\n",
    "\n",
    "public int additionTest(int a, int b){\n",
    "    return a + b;\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from ctxmutants.tokenize import func_tokenize\n",
    "\n",
    "def tokenize_code(code_snippet):\n",
    "    try:\n",
    "        return func_tokenize(code_snippet, lang = \"java\")\n",
    "    except Exception:\n",
    "        return func_tokenize(\"public class Test{%s}\" % code_snippet, lang = \"java\")\n",
    "\n",
    "\n",
    "func_to_tokens_types = tokenize_code(code_example)\n",
    "token_types = next(iter(func_to_tokens_types.values()))\n",
    "\n",
    "tokens, types = token_types[\"tokens\"], token_types[\"types\"]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tokenize_code` function successfully (1) identified the functions in the code snippet, (2) produced a tokenized version of each function and (3) computed syntactic types of each token. In the following, we only consider the function discovered first and before we mutate the tokenized code we investigate the token types in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public : KEYWORDS\n",
      "int : USE_TYPE\n",
      "additionTest : DEF_FUNC\n",
      "( : SYNTAX\n",
      "int : USE_TYPE\n",
      "a : DEF_VAR\n",
      ", : SYNTAX\n",
      "int : USE_TYPE\n",
      "b : DEF_VAR\n",
      ") : SYNTAX\n",
      "{ : SYNTAX\n",
      "return : KEYWORDS\n",
      "a : USE_VAR\n",
      "+ : BOP\n",
      "b : USE_VAR\n",
      "; : SYNTAX\n",
      "} : SYNTAX\n"
     ]
    }
   ],
   "source": [
    "for i, token in enumerate(tokens):\n",
    "    token_type = types[i]\n",
    "    print(\"%s : %s\" % (token, token_type.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that each token is assigned a specific syntactic role based on the context it appears in. For example, the identifier `a` is both tagged as a variable definition and variable usage dependent on the program location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup contextual mutation\n",
    "Contextual mutators are here implemented within two steps. First, we enumerate potential mutant candidates\n",
    "by applying a base mutator. Then, we assign a likelihood of seeing a mutant by running a masked language model.\n",
    "Mutants are produced by sampling according to this likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'code': 'public int additionTest ( int a , int b ) { return a - b ; }',\n",
       "  'location': 13,\n",
       "  'before': '+',\n",
       "  'after': '-',\n",
       "  'score': 0.8357382491308553},\n",
       " {'code': 'public int additionTest ( int a , int b ) { return a * b ; }',\n",
       "  'location': 13,\n",
       "  'before': '+',\n",
       "  'after': '*',\n",
       "  'score': 0.08246741274092674},\n",
       " {'code': 'public int additionTest ( int a , int b ) { return a % b ; }',\n",
       "  'location': 13,\n",
       "  'before': '+',\n",
       "  'after': '%',\n",
       "  'score': 0.07746933939678168},\n",
       " {'code': 'public int additionTest ( int a , int b ) { return a / b ; }',\n",
       "  'location': 13,\n",
       "  'before': '+',\n",
       "  'after': '/',\n",
       "  'score': 0.004324998731436322}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from collections import namedtuple\n",
    "\n",
    "from ctxmutants.mutation import strong_binary_mutation, weak_varmisuse_mutation\n",
    "from ctxmutants.mutation import weak_binary_mutation\n",
    "from ctxmutants.mutation import ContextualBatchMutation\n",
    "from ctxmutants.mutation import mlm_codebert_rerank\n",
    "\n",
    "MutationCandidate = namedtuple('MutationCandidate', [\"tokens\", \"types\", \"mask\", \"location\"])\n",
    "\n",
    "def ctx_mutate(tokens, types, location = None, topK = 5):\n",
    "\n",
    "    # (1) Select location and base mutator\n",
    "    base_mutators = {\"USE_VAR\": weak_varmisuse_mutation, \"BOP\": strong_binary_mutation} # Option: replace strong_binary_mutation by weak_binary_mutation\n",
    "    if location is None: \n",
    "        candidate_locs = [i for i, t in enumerate(types) if t.name in base_mutators]\n",
    "        assert len(candidate_locs) > 0\n",
    "        location = random.choice(candidate_locs)\n",
    "    else:\n",
    "        assert types[location].name in base_mutators\n",
    "\n",
    "    base_mutator = base_mutators[types[location].name]\n",
    "\n",
    "    # (2) Setup mutator with base_mutator and use CodeBert for contextual mutation\n",
    "    mutator = ContextualBatchMutation(base_mutator, mlm_codebert_rerank, lang = \"java\")\n",
    "    mutant_dist = mutator(\n",
    "        [MutationCandidate(tokens, types, None, location)]\n",
    "    )\n",
    "    mutant_dist = mutant_dist[0]\n",
    "\n",
    "    # (3) We report the topK mutants\n",
    "    topK_mutants = sorted(mutant_dist.items(), key = lambda x: x[1], reverse = True)\n",
    "    topK_mutants = topK_mutants[:topK]\n",
    "\n",
    "    output = []\n",
    "\n",
    "    for mutant, prob in topK_mutants:\n",
    "        mutant_tokens = list(tokens)\n",
    "        mutant_tokens[location] = mutant\n",
    "        mutant_code = \" \".join(mutant_tokens)\n",
    "\n",
    "        output.append({\n",
    "            \"code\": mutant_code,\n",
    "            \"location\": location,\n",
    "            \"before\" : tokens[location],\n",
    "            \"after\": mutant,\n",
    "            \"score\" : prob\n",
    "        })\n",
    "\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "ctx_mutate(tokens, types, location = 13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that replacing the addition with a subtraction is the most likely mutation. To see why it is important to restrict the mutation\n",
    "candidates to syntactically fitting candidates, please replace `strong_binary_mutation` by `weak_binary_mutation` and run the code again. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground\n",
    "Now, it is your turn to play with contextual mutations. Use the variable `source_code` to process your own code.\n",
    "After running the next cell, choose a potential mutation location or leave it to the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n",
      "['public', 'void', 'test', '(', 'Object', 'input', ')', '{', 'if', '(', 'input', '==', 'null', ')', '{', 'return', ';', '}', 'handle', '(', 'input', ')', ';', '}']\n",
      "\n",
      "Available mutation locaions:\n",
      "Loc 10 | Token: input  | Type: USE_VAR | Ctx: { if ( input == null\n",
      "Loc 11 | Token: ==  | Type: BOP | Ctx: if ( input == null )\n",
      "Loc 20 | Token: input  | Type: USE_VAR | Ctx: } handle ( input ) ;\n"
     ]
    }
   ],
   "source": [
    "source_code = \"\"\"\n",
    "\n",
    "public void test(Object input) {\n",
    "    if(input == null) {\n",
    "        return;\n",
    "    }\n",
    "    handle(input);\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tokens_types  = next(iter(tokenize_code(source_code).values()))\n",
    "tokens, types = tokens_types[\"tokens\"], tokens_types[\"types\"]\n",
    "\n",
    "print(\"Tokens:\")\n",
    "print(tokens)\n",
    "print()\n",
    "print(\"Available mutation locaions:\")\n",
    "\n",
    "for i, token in enumerate(tokens):\n",
    "    type = types[i]\n",
    "    if type.name in [\"USE_VAR\", \"BOP\"]:\n",
    "        token_ctx = \" \".join(tokens[i-3:i+3])\n",
    "        print(\"Loc %d | Token: %s  | Type: %s | Ctx: %s\" % (i, token, type.name, token_ctx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a mutant location such that the contextual mutator can produce some mutation candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 'public void test ( Object input ) { if ( input != null ) { return ; } handle ( input ) ; }', 'location': 11, 'before': '==', 'after': '!=', 'score': 0.9630580979475805}\n",
      "----\n",
      "{'code': 'public void test ( Object input ) { if ( input <= null ) { return ; } handle ( input ) ; }', 'location': 11, 'before': '==', 'after': '<=', 'score': 0.02740058623154283}\n",
      "----\n",
      "{'code': 'public void test ( Object input ) { if ( input < null ) { return ; } handle ( input ) ; }', 'location': 11, 'before': '==', 'after': '<', 'score': 0.008276679278432718}\n",
      "----\n",
      "{'code': 'public void test ( Object input ) { if ( input >= null ) { return ; } handle ( input ) ; }', 'location': 11, 'before': '==', 'after': '>=', 'score': 0.0006765373083551387}\n",
      "----\n",
      "{'code': 'public void test ( Object input ) { if ( input > null ) { return ; } handle ( input ) ; }', 'location': 11, 'before': '==', 'after': '>', 'score': 0.0005880992340889765}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "mutant_location = 11 # Change here (Set to None if random)\n",
    "\n",
    "mutations = ctx_mutate(tokens, types, location = mutant_location)\n",
    "\n",
    "for mutation in mutations:\n",
    "    print(mutation)\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between mutation types\n",
    "This section also belongs to the playground and, hence, uses the same code and location defined in the previous section.\n",
    "Here, we want to highlight the difference between different mutator types used in neural bug detection, mutation testing and in our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loose mutation (as used in neural bug detection)\n",
      "----------------------------------------------------------------\n",
      "public void test ( Object input ) { if ( input | null ) { return ; } handle ( input ) ; }\n",
      "\n",
      "Strict mutation (as used in mutation testing)\n",
      "----------------------------------------------------------------\n",
      "public void test ( Object input ) { if ( input >= null ) { return ; } handle ( input ) ; }\n",
      "\n",
      "Contextual mutation\n",
      "----------------------------------------------------------------\n",
      "public void test ( Object input ) { if ( input != null ) { return ; } handle ( input ) ; }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For sampling a mutation\n",
    "def sample_mutation(mutation_dist):\n",
    "    random_selection = random.random()\n",
    "    cumsum = 0.0\n",
    "\n",
    "    for key, prob in sorted(mutation_dist.items(), key = lambda x: x[1], reverse=True):\n",
    "        if cumsum + prob >= random_selection: return key\n",
    "        cumsum += prob\n",
    "    \n",
    "    return key # Because of numerical instabilities sum(probs) smaller 1.0\n",
    "\n",
    "\n",
    "assert types[mutant_location].name == \"BOP\", \"Only all three mutation types are supported for BOP\"\n",
    "\n",
    "# Loose mutant\n",
    "loose_mutation_dist = weak_binary_mutation(tokens, mutant_location)\n",
    "loose_mutant = sample_mutation(loose_mutation_dist)\n",
    "\n",
    "# Strict mutant\n",
    "strong_mutation_dist = strong_binary_mutation(tokens, mutant_location)\n",
    "strong_mutant = sample_mutation(strong_mutation_dist)\n",
    "\n",
    "# Contextual mutant\n",
    "\n",
    "ctx_mutation_dist = {m[\"after\"] : m[\"score\"] for m in mutations}\n",
    "ctx_mutant = sample_mutation(ctx_mutation_dist)\n",
    "\n",
    "for mutant_type, mutant in [(\"Loose mutation (as used in neural bug detection)\", loose_mutant) , (\"Strict mutation (as used in mutation testing)\", strong_mutant), (\"Contextual mutation\", ctx_mutant)]:\n",
    "    print(mutant_type)\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "\n",
    "    mutate_tokens = list(tokens)\n",
    "    mutate_tokens[mutant_location] = mutant\n",
    "    mutate_code = \" \".join(mutate_tokens)\n",
    "\n",
    "    print(mutate_code)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e49e4b1338c536a3b24fc51f719eff5e9bb6f42833c3172f334ab85d121b9a3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
